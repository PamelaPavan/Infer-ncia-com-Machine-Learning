<h1 align="center">ğŸ§  Sistema de InferÃªncia com Machine Learning</h1>

<h2 align="center"> <i>PrevisÃµes Inteligentes para PrecificaÃ§Ã£o de Reservas de HotÃ©is com SageMaker e AWS</i></h2>

![Imagem|Compass](assets/compass.png)

## ğŸ“‹ Ãndice

- [Objetivo](#-objetivo)
- [DescriÃ§Ã£o](#-descriÃ§Ã£o)
- [Como rodar](#-como-rodar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Tecnologias utilizadas](#-tecnologias-utilizadas)
- [Arquitetura do projeto](#ï¸-arquitetura-do-projeto)
- [Dificuldades](#ï¸-dificuldades)
- [Agradecimentos](#-agradecimentos)
- [Autores](#-autores)

## ğŸ¯ Objetivo
Construir um sistema de inferÃªncia para classificar reservas de hotÃ©is com base em faixas de preÃ§os do [dataset do kaggle](https://www.kaggle.com/datasets/ahsan81/hotel-reservations-classification-dataset/).

## ğŸ“– DescriÃ§Ã£o
1. ConstruÃ§Ã£o do Modelo de ClassificaÃ§Ã£o (Treinamento Local):
    - Realizamos o treinamento dos modelos de machine learning localmente, evitando gastos na AWS durante a fase de experimentaÃ§Ã£o e ajuste de hiperparÃ¢metros.
    - Avaliamos vÃ¡rios modelos, incluindo KNN, Decision Tree, Random Forest e XGBoost.
    - Escolhemos o XGBoost como o modelo final devido Ã  sua melhor performance.

2. Armazenamento do Modelo Treinado no S3:
    - ApÃ³s o treinamento, armazenamos o modelo XGBoost no Amazon S3 para posterior uso.

3. CriaÃ§Ã£o do Ambiente Docker na AWS:
    - Criamos um ambiente Docker na Amazon Web Services (AWS) para implementar nossa API.

4. Desenvolvimento da API de InferÃªncia:
    - Desenvolvemos um serviÃ§o em Python, utilizando o framework HTTP FastAPI.
    - A API carregou o modelo XGBoost treinado do Amazon S3 e expÃ´s um endpoint para realizar inferÃªncias.
    - O endpoint aceita requisiÃ§Ãµes POST com a rota /api/v1/predict e recebe um JSON no corpo da requisiÃ§Ã£o contendo informaÃ§Ãµes como o nÃºmero de adultos, o nÃºmero de crianÃ§as e o tipo de plano de refeiÃ§Ãµes.
    - A resposta da API segue o formato: {"result": 1}.

5. Deploy do ServiÃ§o na AWS: 
    - Realizamos o deploy da API na AWS para que possa ser acessada remotamente.


## ğŸš€ Como rodar

1. PrÃ©-requisitos

    - Docker
    - Python
 
2. Clone o repositÃ³rio:

    ```bash
    git clone -b grupo-7 https://github.com/Compass-pb-aws-2024-ABRIL/sprints-4-5-pb-aws-abril.git
    cd sprints-4-5-pb-aws-abril
    ```
 
3. Para rodar:
    - Docker:
    

    Navegue para a pasta onde estÃ¡ localizado o Dockerfile.
    Construa a imagem Docker:
    
    ```bash
    docker build -t fastapi-docker .
    ```
    
    Rode o contÃªiner:
    
    ```bash
    docker run -p 80:80 fastapi-docker
    ```
    
    - Ou utilize os scripts .sh como helpers.

4. Acesse no navegador:

    Depois de montado, faÃ§a o download do seu modelo que estÃ¡ no S3 e Ã© possÃ­vel verificar a inferÃªncia via Postman. O endpoint Ã© um mÃ©todo POST na rota localhost/api/v1/predict que deve receber um JSON no corpo seguindo o seguinte formato:
    ```JSON
    {
        "no_of_adults": 2,
        "no_of_children": 0,
        "no_of_weekend_nights": 2,
        "no_of_week_nights": 3,
        "type_of_meal_plan": "Not Selected",
        "required_car_parking_space": 0,
        "room_type_reserved": "Room_Type 1",
        "lead_time": 5,
        "arrival_year": 2018,
        "arrival_month": 11,
        "arrival_date": 6,
        "market_segment_type": "Online",
        "repeated_guest": 0,
        "no_of_previous_cancellations": 0,
        "no_of_previous_bookings_not_canceled": 1,
        "no_of_special_requests": 1
    }
    ```
    A resposta estarÃ¡ no seguinte formato:
    ```JSON
    {
        "result": 3
    }
    ```
    Sendo: 
    `result: 1` para preÃ§os â‰¤ 85; 
    `result: 2` para preÃ§os entre 80 e 115; 
    `result: 3` para preÃ§os >= 115.


5. ML & AI:
    - Navegue para a pasta Python e instale as bibliotecas necessÃ¡rias.

    <br>
    
    ```bash
    pip install -r requirements.txt
    ```
    
    - Ou rode o arquivo setup.ipynb.
    Ajuste suas credenciais de acordo com o .env.example.

## ğŸ“‚ Estrutura do Projeto

 
```bash
assets/                                 # imagens utilizadas no Readme
src/
â”œâ”€ api/
â”œâ”€â”œâ”€ docker/                            # configuraÃ§Ãµes Dockerfile
â”œâ”€â”œâ”€ docker-compose.yml                 # configuraÃ§Ãµes docker-compose
â”œâ”€â”œâ”€ main.py                            # configuraÃ§Ã£o FastAPI
â”œâ”€â”œâ”€ requirements.txt                   # dependÃªncias Python para a API
â”œâ”€ python/
â”œâ”€â”œâ”€ data/                              # arquivos .csv antes e depois do processamento
â”œâ”€â”œâ”€ logs/                              # logs de cada modelo registrados durante o tuning
â”œâ”€â”œâ”€ models/                            # modelos iniciais/tuning do DT, KNN, RF e XGBoost
â”œâ”€â”œâ”€ sagemaker/
â”œâ”€â”œâ”€â”œâ”€ eda.ipynb                        # analise dos dados e algumas manipulaÃ§Ãµes das tabelas
â”œâ”€â”œâ”€â”œâ”€ random_forest.ipynb              # treinamento com 2Â° melhor acurÃ¡cia compatÃ­vel com o SageMaker
â”œâ”€â”œâ”€â”œâ”€ rds.ipynb                        # armazenamento do dataset original e alterado no AWS RDS
â”œâ”€â”œâ”€â”œâ”€ train_script.py                  # script necessÃ¡rio para fazer o treinamento RF com SageMaker
â”œâ”€â”œâ”€â”œâ”€ xgboost.ipynb                    # treinamento com melhor acurÃ¡cia compatÃ­vel com o SageMaker
â”œâ”€â”œâ”€ scripts/                           # funÃ§Ãµes utilizadas recorrentemente durante os treinamentos
â”œâ”€â”œâ”€ .env.example                       # armazenar variÃ¡veis do ambiente
â”œâ”€â”œâ”€ requirements.txt                   # dependÃªncias Python para AI & ML
â”œâ”€â”œâ”€ setup.ipynb                        # instalaÃ§Ã£o das bibliotecas que serÃ£o utilizadas
README.md
```


## ğŸ’» Tecnologias utilizadas

1. Tecnologias de Machine Learning e Bibliotecas de Python:
    - XGBoost: Algoritmo de aprendizado de mÃ¡quina utilizado para a classificaÃ§Ã£o.
    - Scikit-Learn: Utilizado para processamento dos dados, avaliaÃ§Ã£o e modelos como KNN, Random Forest e Decision Tree.
    - Python: Linguagem de programaÃ§Ã£o principal do projeto.


2. Ferramentas e Tecnologias para Desenvolvimento e Deploy:

    - AWS S3: Armazenamento do modelo treinado.
    - AWS EC2: Para a execuÃ§Ã£o do ambiente Docker e hospedagem da API.
    - AWS RDS: Banco de dados MySQL.
    - AWS CLI: Interface de comando para o provisionamento da EC2.
    - Docker: CriaÃ§Ã£o de um ambiente containerizado para a implementaÃ§Ã£o da API.
    - FastAPI: Framework web em Python utilizado para o desenvolvimento da API de inferÃªncia.
    - Boto3: AWS SDK para o Python.


3. Controle de VersÃ£o e ColaboraÃ§Ã£o:
    - Git: Controle de versÃ£o do cÃ³digo-fonte do projeto.
    - Trello: OrganizaÃ§Ã£o e distribuiÃ§Ã£o de tarefas.

4. Outros:
    - JSON: Formato de dados utilizado nas requisiÃ§Ãµes e respostas da API.

## ğŸ—ï¸ Arquitetura do projeto
![Imagem|Diagrama](assets/arquitetura.png)

## ğŸ› ï¸ Dificuldades
1. <strong>CompreensÃ£o e ImplementaÃ§Ã£o de Modelos de Machine Learning</strong>:
Ajustar os hiperparÃ¢metros para otimizar a performance exigiu um esforÃ§o significativo, com vÃ¡rias iteraÃ§Ãµes e experimentos necessÃ¡rios para alcanÃ§ar resultados satisfatÃ³rios.

2. <strong> ConexÃ£o do RDS com o banco de dados : </strong> A maior parte dos integrantes do grupo obteve problemas ao tentar realizar esta conexÃ£o.

3. <strong>ExecuÃ§Ã£o AWS SageMaker com LocalSession( )</strong>:
     Configurar e executar nossos scripts de machine learning no AWS SageMaker utilizando o LocalSession( ) apresentou dificuldades tÃ©cnicas e nÃ£o foi possÃ­vel ser realizada atÃ© dia 20, um dia apÃ³s a disponibilizaÃ§Ã£o deste [link](https://github.com/aws-samples/amazon-sagemaker-local-mode/blob/main/WINDOWS_INSTALLATION.md) no canal de tira-dÃºvidas. Depois foi possÃ­vel rodar o LocalSession( ) utilizando WSL. PorÃ©m, como o tempo estava apertado nÃ£o foi possÃ­vel implementar completamente para utilizar no projeto.


## ğŸ™ Agradecimentos

Ã‰ com imensa satisfaÃ§Ã£o que o grupo-7 agradece Ã  CompassUOL por providenciar o acesso aos cursos da Udemy, que geraram o aprendizado e desenvolvimento necessÃ¡rio para esta implementaÃ§Ã£o e muito mais.

## ğŸ‘¥ Autores

**PÃ¢mela Aliny Cleto Pavan**
- GitHub: https://github.com/PamelaPavan
